# data
data:
  instruct_data: "/home/rileywebb/sonnet-roleplay-dataset.jsonl"  # Update with your dataset path
  data: ""  # No pretraining data used
  eval_instruct_data: "/home/rileywebb/sonnet-roleplay-dataset-eval.jsonl"  # Optionally update if you have a validation set

# model
model_id_or_path: "/home/rileywebb/mistral-finetune/output-dir/suada_rp_tune/consolidated"  # Update with your model path
lora:
  rank: 128

# optim
seq_len: 32768  # Ensure this matches the dataset's average token length
batch_size: 1  # Keep it small for gradient accumulation
max_steps: 1000  # Increase training steps to focus more on learning the style and flow of this data
optim:
  lr: 2e-4  # Slightly reduce learning rate to prevent overwriting the model's previous fine-tuning; smaller LR will focus on finer adjustments
  weight_decay: 0.01
  pct_start: 0.05  # Warmup for 5% of the total steps

# other
seed: 42  # For reproducibility, update the seed for this run
log_freq: 1
eval_freq: 100  # Evaluate frequently to ensure the model isn't overfitting
no_eval: False
ckpt_freq: 100  # Save checkpoints more frequently for potential rollbacks

save_adapters: False  # save only trained LoRA adapters. Set to `False` to merge LoRA adapter into the base model and save full fine-tuned model

run_dir: "/home/rileywebb/mistral-finetune/output-dir/sonnet-roleplay-tune"  # Fill

wandb:
  project: "suada" # your wandb project name
  run_name: "sonnet_roleyplay_tune" # your wandb run name
  key: "35a03d1d2de16b755251b46657e20294b34e1305" # your wandb api key
  offline: False
